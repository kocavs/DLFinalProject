# DLFinalProject
The goal is to finetune the models RoBerta, Bert and DistilBert for sentiment classification tasks. By implementing the tweet_eval dataset and three pretrained models with transformer, we conclude that different language models can have varying levels of ability to interpret emotions.

## Prerequisites:
```
pip install transformers
pip install datasets
```

## Pretrained model and dataset used:
* BERT, RoBERTa-base, DistilBERT
* "tweet_eval" dataset
* 

